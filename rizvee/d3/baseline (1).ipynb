{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b99ab988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "import numpy as np\n",
    "#from imgaug import augmenters as iaa\n",
    "#import cv2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#import seaborn as sns\n",
    "import pandas as pd \n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae836231",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = r'D:/dataset/Train'\n",
    "VAL_PATH = r'D:/dataset/Test'\n",
    "BATCH_SIZE=16\n",
    "r=4\n",
    "c=4\n",
    "#CATEGORIES = ['Air_trapping', 'Aortic_elongation','COPD_Signs','Calcified_granuloma','Callus_rib_fracture','Hiatal_hernia','Kyphosis','Laminar_atelectasis','Normal','Pleural_effusion','Scoliosis','Vascular_hilar_enlargement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c644fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34387 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_batches = train_datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                                  class_mode='categorical', \n",
    "                          \n",
    "                                                  batch_size=BATCH_SIZE, \n",
    "                                                  target_size=(224, 224),\n",
    "                                                  shuffle=False,\n",
    "                                                  seed=42\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d74671cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8597 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_batches = val_datagen.flow_from_directory(VAL_PATH,\n",
    "                                                class_mode='categorical', \n",
    "                                        \n",
    "                                                batch_size=BATCH_SIZE, \n",
    "                                                target_size=(224, 224),\n",
    "                                                shuffle=False,\n",
    "                                                seed=42\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dfaff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87192750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5420a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                6156      \n",
      "=================================================================\n",
      "Total params: 14,720,844\n",
      "Trainable params: 14,720,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def vgg():\n",
    "    base_model = VGG16(weights='imagenet',include_top=False,pooling='avg',input_shape=(224,224,3))\n",
    "    predictions=Dense(12,activation='softmax',trainable=True)(base_model.output)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=True\n",
    "    model=Model(inputs=[base_model.input], outputs=[predictions])\n",
    "    \n",
    "    optim = tf.keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-4)\n",
    "    loss_func = 'categorical_crossentropy'\n",
    "    \n",
    "    model.compile(optimizer=optim,loss=loss_func,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=None\n",
    "model = vgg()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34f70d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('adam_baseline_vgg.h5', monitor='val_accuracy', save_best_only=True, mode='max'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, verbose=1, patience=5, mode='max')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ba6d39c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   2/2149 [..............................] - ETA: 3:21 - loss: 1.9357 - accuracy: 0.0625  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0559s vs `on_train_batch_end` time: 0.1316s). Check your callbacks.\n",
      "2149/2149 [==============================] - 518s 241ms/step - loss: 0.9421 - accuracy: 0.7930 - val_loss: 0.9022 - val_accuracy: 0.7943\n",
      "Epoch 2/30\n",
      "2149/2149 [==============================] - 449s 209ms/step - loss: 0.9104 - accuracy: 0.7943 - val_loss: 0.9136 - val_accuracy: 0.7943.8699 -  - ETA: 4:31 - loss: 0.8801 - accuracy: 0.80 - ETA: 4:31 - ETA: 3:30 - ETA: 3:22 - loss: 0.8755 -  - ETA - E - E - ETA: 1:57 - loss: 0.8844 - accuracy:  - ETA:  - ET -  - ETA: 24s - loss: 0.8993 - accuracy: 0.79 - ETA: 23s - loss: 0.8986 - accuracy: 0. - ETA: 23s - loss: 0.90 - ETA: 18s - loss: 0.9008 - a - ETA: 16s - loss: 0.9030 - accurac - ETA: 14s - loss: 0.9019 - - ETA: 10s - loss: 0.9030 - accuracy: 0. - ETA: 10 - ETA: 6s - loss: 0 - ETA: 4s - loss: 0.9007 - accura - ETA: 3s - loss: 0.9042  - ETA: 1s - loss: 0.9086 - ac - ETA: 0s - loss: 0.9107 - accuracy: 0.79 - ETA: 0s - loss: 0.9104 - accuracy: 0.79\n",
      "Epoch 3/30\n",
      "2149/2149 [==============================] - 441s 205ms/step - loss: 0.9029 - accuracy: 0.7939 - val_loss: 0.8949 - val_accuracy: 0.794317 - loss: - ETA: 2:47 - loss: 0.9018 -  - E - ETA: 2:41 - loss: 0.8997  - ETA: 2:39 - loss: 0.8976 - accu - ETA: 2:38 - loss: 0.8981 -  - ETA: 2:36 - loss: 0.8972 - accuracy - ETA: 2:36 - loss: 0.8952 - ac - ETA: 2:34 - loss: 0.9023 - accu - ETA: 2:33 - loss: 0.9030 - accuracy - ETA: 2:32 - loss: - ETA: 2:30 - loss: 0.9072  - ETA: 2:28 - loss: 0.9047 - accuracy: 0.79 - ETA: 2:28 - loss: - ETA: 2:25 - - ETA: 2:22 - l - ETA: 1: - ETA: 1:31 - loss: 0.9015 - accuracy:  - ETA: 1:30 - ETA: 1:27 - loss: 0.8970 -  - ETA: 58s - loss: 0.8977 - accuracy: 0.794 - ETA: 57s - loss: 0.8988 - accuracy: 0.79 - ETA: 57s - loss: 0.8992 - accurac - ETA: 55s - loss - ETA: 33s - loss: 0.9100 - accur - - ETA: 22s - loss: 0.9078 -  - ETA: 19s - loss: 0.9071 - accuracy: 0.79 - ETA: 19s - loss: - ETA: 7s - loss: - ETA: 0s - loss: 0.9019 - accuracy: 0. - ETA: 0s - loss: 0.9026 - accuracy:  - ETA: 0s - loss: 0.9029 - accuracy: 0.79\n",
      "Epoch 4/30\n",
      "2149/2149 [==============================] - 435s 202ms/step - loss: 0.8945 - accuracy: 0.7939 - val_loss: 0.9027 - val_accuracy: 0.7943 ETA: 6: - ETA: 6:25 - loss: 0.7178 - accuracy:  - ETA: 6:24 - loss: 0.7030 - accuracy: 0.85 - ETA: 6:24 - loss: 0.6982 - ac - E - ETA: 5:28 - loss: 0.7612 - accura - ETA: 5:27 - loss: - ETA: 5:25 - loss: - ETA: 5:22 - loss: 0.7603  - ETA: 5:16 - loss: 0.7878 - ac - ETA: 5:10 - loss: 0.7904 - accuracy:  - ETA: 5:10 - loss: 0.7919 - accuracy - ETA: 5:09 - ETA: 4:35 - loss: 0.7718 - accuracy:  - ETA: 4:35 - loss: 0.7891 - accuracy:  - ETA: 4:30 - loss: 0.7820 -  - ETA: 4:15 - loss: 0.765 - ETA: 4:13 - loss: - ETA: 4:07 - loss: 0.7769 - accuracy - ETA: 4:06 - - ETA: 4:03 - loss: 0.7702 - accuracy - ETA: 4:02 - loss: 0.7705 - ac - ETA: 4:01 - loss: 0.7771 - accu - ETA: 4:00 - - - ETA: 2:43 - loss: 0.8492 - accuracy: 0. - ETA: 2:42 - los - ETA: 2:39 - loss: - ETA: 2:33 - loss: 0.8537 - accuracy: 0. - ETA: 2:32 - loss: - - ETA: 2:26 - loss: 0.8 - ETA: 2:24 - loss: 0.8471 - accuracy:  - - ETA: 1:57 - loss: 0.8530 - accuracy:  - ETA: 1:56 - loss: 0.8533 - ac - ETA: 1:55 - loss: 0.8504  - ETA: 1:53 - loss: 0.85\n",
      "Epoch 5/30\n",
      "2149/2149 [==============================] - 435s 203ms/step - loss: 0.8944 - accuracy: 0.7939 - val_loss: 0.8854 - val_accuracy: 0.7943: 4:47 - loss: 0.8713  - - ETA: 4: - ETA: 4:33 - loss: 0.871 - ETA: 4:27 - ETA: 2:38 - loss: 0 - ETA: 2:36 - loss: 0.8 - ETA: 2:34 - loss: 0.8646 - ac - E - ETA: 2:11 - loss: - ETA: 1:38 - loss: 0.885 - ETA: 1:36 - loss: 0 - ETA: 1:34 - loss: - ETA: 1:32 - loss: 0.8758 - accu - ETA: 1:04 - loss: 0.881 - ETA: 1 - ETA: 33s - loss: 0.8850 - accurac - ETA: 31s - loss: 0.8916 - accu - ETA: 11s - los\n",
      "Epoch 6/30\n",
      "2149/2149 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.7943   ETA: 5:09 - - ETA: 5:01 - loss: 0.9261 - accuracy: 0.78 - ETA: 5:01 - - ETA: 4:58 - ETA: 4:55 - loss: 0.9295 - accura - ETA: 4:54 - loss: 0.9237 - ac - ETA:  - ETA:  - ETA: 4:46 - loss: 0.9176 - accuracy - ETA - ETA: 4:41 - loss: 0.9147 - accuracy: 0. - ETA: 4:40 - loss: 0 - ETA: 4:38 - loss: 0.9224 - accu - ETA: 4:37 - loss: 0.9331 - accuracy: 0. - ETA: 4:37 - loss: 0.9311 - accuracy:  - E - ETA: 4: - ETA: 4:29 - loss: 0.9 - ETA: 4:26 - loss: 0.9201  - ETA: 4:25 - loss: 0.9157 - accu - ETA: 4:24 - loss: 0.9153 - accura - ETA: 4:23 - loss: 0.9106 -  - ETA: 4:21 - loss: 0 - ETA: 4:10 - loss: 0.9240 - accuracy: 0.78 - ETA: 4:10 - loss: 0.923 - ETA: 4:08 - - ETA: 4:05 - loss: 0.9270 - accura - E - ETA: 1:18 - ETA: 1:15 - loss: 0.8971 - ac - ETA: 1:14 - loss: 0.894 - ETA: 1:12 - loss: 0 - - ETA: 1:06 - loss: \n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "2149/2149 [==============================] - 435s 203ms/step - loss: 0.8846 - accuracy: 0.7943 - val_loss: 0.8872 - val_accuracy: 0.7943\n",
      "Epoch 7/30\n",
      "2149/2149 [==============================] - 435s 202ms/step - loss: 0.8750 - accuracy: 0.7939 - val_loss: 0.8805 - val_accuracy: 0.7943 ETA: 5:12 - - - ETA: 5:01 - - ETA: 4:58 - loss: 0 - ETA: 4:55 - l - ETA: 4: - ETA: 4:45 - loss: 0.9133 - accuracy: 0.78 - ETA: 4:45 - loss: 0.9122  - ETA: 4:34 - loss: 0.8818 - ac - ETA: 4:11 - loss: 0.8907 - accuracy:  - ETA: 4:11 - los - ETA: 4:08 - loss: 0.902 - ETA: 4:06 - loss: 0.9028 - accuracy - E - ETA: 4:01 - loss: 0.8911 - accuracy: 0.78 - ETA: 4: - ETA: 2:52 - loss: 0.8 - E - ETA: 2:11 - loss: 0.8766 - ac - ETA: 2:10 - loss: 0.8735 - accuracy:  - ETA: 2:09 - loss: 0.8721 - accura - ETA: 2:04 - loss: 0.8746 - accuracy: 0.79 - ETA: 2:04 - loss: 0.8742 -  - E - ETA: 1:54 - ETA: 1:51 - loss: 0.8791 - accu - ETA: 1:50 - loss: 0.8780 - accuracy - ETA: 1:49 - loss: 0 - ETA: 1:29 - loss: 0.8711 -  - ETA: 1:28 - loss: 0.8709 - accuracy: 0. - ETA: 1:27 - loss: 0.8702 - accuracy: 0. - ETA: 1:27 - loss: - ETA: 1:24 - ETA: 59s - loss - ETA: 54s - loss: 0.8622 - accurac - ETA: 52s - loss: 0.8603 - accuracy: 0 - ETA: 51s - loss: 0.8600 - a - ETA: 49s - loss: 0.8581 - accur - - ETA: 38s - loss: 0.8554 - accuracy: 0.79 - ETA: - ETA: 22s - loss: 0.872 - ETA: 18s - loss: 0.8686 - accuracy: 0.79 - ETA: 1s - loss: 0.8743 - accura - ETA: 0s - loss: 0.8759 - accuracy\n",
      "Epoch 8/30\n",
      "2149/2149 [==============================] - 435s 203ms/step - loss: 0.8708 - accuracy: 0.7943 - val_loss: 0.8799 - val_accuracy: 0.7943 loss: - ETA: 5:29 - los - ETA: 5:27 - loss: 0.9199 - accuracy:  - ETA: 5:26 - loss: 0.9 - ETA: 5:24 - loss: 0.9072  - ETA: 5:22 - loss: 0.9148 - accura - ETA: 5:21 - loss: 0.9071 - accuracy - ETA: 5:21 - loss: 0 - ETA: 5:18 - loss: 0.9045 - accura - ETA: 5:17 - loss: 0.9077 - accuracy: 0. - ETA: 5:17 - loss: 0.9048 - accuracy: 0. - ETA: 5:17 - loss: 0.9059 - accuracy: 0.79 - ETA: 5:16 - loss: 0.9045 - accura - ETA: 5:11 - loss: 0.9 - ETA: 5:09 - loss: 0.9073 - accuracy:  - ETA: 5:04 - loss: 0.8 - ETA: 5:02 - loss: 0.8912 - accura - ETA: 5:01 - l - E - ETA: 4:41 - loss: 0 - ETA: 4:35 - loss: 0.8643 - ac - ETA: 4:33 - loss: 0.8609 - accuracy:  - E - - ETA: 4:20 - los - ETA: 4:17 - ETA - ETA: 4:06 - loss: 0.8534 - accuracy - ETA: 4:05 - loss: 0.8530  - ETA: 2:58 - loss: 0.8724 - accuracy: 0. - ETA: 2:58 - loss: 0.8713 - accu - ETA: 1: - ETA: 1:00 -  - ETA: 54s - loss: 0.8816 - accuracy: 0.7 - ETA: 54s - loss: 0. - ETA: 49s - loss: 0.8851 - accuracy: 0 - ETA: 48s - loss: 0.8834 - accu - ETA: 46s - loss: 0.8848 - accuracy: 0 - ETA: 45s - loss: 0. - ETA: 41s - loss:  - ETA: 36s - loss: 0.8774 - ETA: 33s - loss: 0.8764 - ac - ETA: 30s - loss: 0.8776 - accuracy:  - ETA: 29s - loss: 0.8756 - accuracy: - ETA: 1s - loss: 0.8\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 435s 202ms/step - loss: 0.8687 - accuracy: 0.7943 - val_loss: 0.8800 - val_accuracy: 0.7943oss: 0.6890 - accuracy: 0.84 - ETA: 6:25 - loss: 0.684 - ETA: 6:12 - ETA: 6:10 - loss: 0.7 - ETA - ETA: 5:56 - loss: 0.8084 - accuracy - ETA: 5: - ETA: 5:47 - ETA: 5:44 - loss: 0.810 - ETA: 5:38 - l - ETA: 5:35 - loss: 0.8320 - accuracy: 0. - ETA: 5:35 - loss: 0.8 - - ETA: 5:29 - loss: 0.8499 - accuracy: 0. - ETA: 5:28 - los - ETA: 5:26 - ETA: 5:14 - loss: 0.834 - ETA: 5:12 - loss: - ETA: 5:09 - l - ETA: 5:07 - loss: 0.8347 - accura - ETA: 5:06 - loss: 0.8 - ETA: 5:04 - loss: 0.8528 - accu - ETA: 5:02 - loss: 0.8529 - accuracy: 0. - ETA: 5:02 - loss: 0.850 - ETA - ETA: 4:56 - loss: 0.8383  - ETA: 4:55 - loss: 0.8401 - accuracy:  - - ETA: 4:41 - loss: 0.8440 - accuracy: 0.80 - ETA: 4:41 - ETA: 4:38 - loss: 0.8454 -  - ETA - ETA: 4:33 - loss: 0.8537 - accuracy - ETA: 4:28 - loss: 0.8811 - accuracy: 0.79 - ETA: 4:27 - l - ETA: 4:24 - loss: 0 - ETA: 4:22 - loss: 0 - ETA: 4:16 - loss: 0.8753 - accura - ETA: 4:15 - loss: 0.8745  - - ETA: 4:04 - loss: 0.8969 - ac - ETA: 4:03 - loss: 0.8 - ETA - ETA: 3:01 - loss: 0.9012 - accu - E - E - ETA: 1:20 - ETA: 1:17 - loss: 0.8891 - accuracy: 0. - ETA: 1:16 - loss: 0.8884 - accuracy - ETA: 1:16 - loss: 0.8902 - accuracy:  - ETA: 38s - loss:  - ETA: 34s - loss: 0.8839 - ETA: 21s - loss: 0 - ETA: 5s - loss: 0.8720 - accu - ETA:  - ETA: 0s - loss: 0.8696 - accuracy\n",
      "Epoch 10/30\n",
      "2149/2149 [==============================] - 428s 199ms/step - loss: 0.8672 - accuracy: 0.7943 - val_loss: 0.8795 - val_accuracy: 0.79433:36 - loss: 0.8449 - ac - ETA: 3:35 - loss: 0.8 - ETA: 3:33 - loss: 0.8362 - accuracy: 0. - ETA: 3:32 - loss: 0.8351 - accu - ETA: 3:31 - loss: 0.8341 - accuracy:  - ETA: 3: - ETA: 3:02 - loss: 0.8538 - accuracy: 0. - ETA: 3:01 - loss: 0 - ETA: 2:29 - - ETA: 2:09 - loss: 0 - ETA:  - ETA:  - ETA: 43s - loss: 0.8560 - accuracy: 0.79 - ETA: 43s - loss: 0.8590 - a - ETA: 40s - loss: 0.8594 - accuracy: -  - ETA: 31s - ETA: 24s - loss: 0.8614 - accur - ETA - ETA: 15s - loss: 0.8649 - acc - ETA: \n",
      "Epoch 11/30\n",
      "2149/2149 [==============================] - ETA: 0s - loss: 0.8687 - accuracy: 0.7938   ETA - ETA:  - ETA: 5:59 - loss: 0.8058  - ETA: 5:58 - loss: 0.781 - ETA: 5:56 - loss: 0.785 - - ETA: 5:38 - ETA: 5:35 - - ETA: 5:15 - - ETA: 4:47 - loss: 0.9332 - accuracy - E - ETA: 4:42 - loss: 0.9278 - accu - ETA: 4:41 - loss: 0.9246 - ac - ETA: 4:40 - loss: 0.9224 - accuracy: 0.78 - ETA: 4:40 - loss: - ETA: 4:33 - loss: 0.8957 - accuracy: 0. - ETA: 4:32 - loss: 0.8937  - ETA: 4:31 - loss: 0.9028 - accuracy: 0. - ETA: 4:30 - loss: 0.9071 - accuracy: 0.78 - ETA: 4:30 - loss: 0.9061 -  - ETA: 4:03 - ETA: 4:00 - los - ETA:  - ETA: 3:50 - loss: 0.8871 - ac - ETA: 3:48 - los - E - ETA: 3:38 - loss: 0.8957 - accuracy: 0. - ETA:  - ETA: 3:34 - loss: 0.8 - - ETA: 3:28 - loss: 0.8974 - accuracy - ETA: 3:27 - loss: 0.8948 - accuracy: 0.78 - ETA: 3:27 - loss: 0.8942 -  - ETA: 2:47 - los - ETA: 2:44 - loss: 0.8799 - accuracy:  - ETA: 2:44 - loss: 0.8784 - accu - - ETA - ETA: 1: - ETA: 1:06 - loss: 0.8825 - accuracy - ETA: 1:05 - loss: 0.8822 -  - ETA: 1:04 - loss: 0.8 - ETA: 1 - ETA: 57s - loss: 0. - ETA: 44s - loss: 0.8866 - accu - ETA: 42s - loss: 0.8835 - accuracy:  - ETA: 41s - loss: 0.8830 - accuracy: 0.7 - ETA: 40s - loss: 0.8820 - accura - ETA: 39s - loss: 0.8806 - accuracy: - ETA: 29s - loss: 0.8747 - accuracy:  - ETA: 28s - loss: 0.8743 - a - ETA: 25s - loss: 0.8719 - accuracy: 0.793 - ETA: 25s - loss: 0.8715 - accuracy: 0.793 - ETA: 25s - loss: 0.8723 - ETA: 21s - loss: 0. - ETA: 17s - loss: 0.8683 - accuracy: 0. - ETA: 16s - loss: 0.8671 - accuracy: 0 - ETA: 15s - loss: 0.8686 -  - ETA: 12s - loss: 0.87 - ETA - ETA: 1s - loss: 0.8704 \n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8687 - accuracy: 0.7938 - val_loss: 0.8789 - val_accuracy: 0.7943\n",
      "Epoch 12/30\n",
      "2149/2149 [==============================] - 428s 199ms/step - loss: 0.8668 - accuracy: 0.7938 - val_loss: 0.8789 - val_accuracy: 0.7943s: 0.8692  - ETA: 5:26 - loss: 0.8738 - accuracy - ETA: 5:26 - loss: 0.8673 - accu - ETA: 5:25 - loss: 0.8574 - accura - ETA: 5:24 - loss: 0.8622 - accuracy: 0.80 - E - ETA: 5:20 - loss: 0.8603 - accuracy - ETA: 5:19 - loss: 0.865 - ETA: 5:17 - - ETA: 5:06 - los - ETA: 4: - ETA: 4:55 - l - ETA: 4:27 - loss: - ETA:  - ETA: 4:21 - los - ETA: 4:18 - ETA: 4:07 - ETA: 4:04 - loss: 0.8275 - accu - ETA - ETA: 3:54 - loss: 0.8435  - ETA: 3:48 - loss: 0.8297 - accu - ETA: 3:47 - loss: 0.8334 - accuracy: 0. - ETA: 3:47 - loss: 0.8414 -  - ETA: 3:28 - l - ETA: 3:13 - loss: 0.853 - - ETA: 3:07 - loss: 0.8564 - accura - ETA: 3:06 - loss: 0 - ETA: 3:04 - loss: 0.8548 -  - ETA: 3:02 - loss: 0.8540 - accuracy: 0.80 - ETA: 3:02 - loss: 0.8 - ETA: 3:00 - - ETA: 2:57 - loss: 0.8590 - accura - ETA: 2:56 - loss: 0.8 - ETA: 2:54 - l - ETA: 1:04 - loss: - ETA: 1:02 - loss: 0.881 - ETA: 1:00 -  - ETA: 54s - loss: 0.8775 - accuracy: - ETA: 53s - loss: 0.8787 - accuracy: 0.791 - ETA: 53s - loss:  - ETA: 48s - loss: 0.8763 - accurac - ETA: 47s - loss: 0.8732 - ac - ETA: 44s - loss: 0.8728 - accuracy: 0.793 - ETA: 44s - loss: 0.8724 - ETA: 40s - loss: 0.8690 - accuracy: 0 - ETA: 39s - loss: 0.8686 - accuracy: 0 - ETA: 38s - loss: 0.8680 - accuracy: 0. - ETA: 38s - loss: 0.8677 - ETA: 34s - loss: 0.8690 - ac - ETA: 32s - loss: 0.8702 - accuracy: 0 - ETA: 31s - loss: 0.8685 - accuracy: 0.7 - ETA: 30s - loss: 0.8676 - accurac - ETA: 28s - loss: 0.8699 - accuracy - - ETA: 19s - loss: 0.8712 - accuracy: 0.792 - ETA: 19s - loss: 0.8709 - accur - ETA: 17s - loss: 0.87 - ETA: \n",
      "Epoch 13/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8650 - accuracy: 0.7943 - val_loss: 0.8789 - val_accuracy: 0.7943 loss: - ETA:  - ETA: 58s - loss - ETA: 53s - loss: 0.8538 - acc - ET - ETA: 43s - loss: 0.856 - ETA: 40s - loss: 0 - ETA - ETA: 28s - loss: 0.8 - ETA: 24s -  - ETA: 18s - loss: 0.8587 - accuracy: 0. - ETA: 17s - loss: 0.861 - ETA: 14s - loss: 0.8671 - accuracy: 0. - ETA: 13s - loss: 0.8658 - accuracy: 0.79 - ETA: 13s - loss: 0.866 - ETA: 5s - loss: 0.8629 - \n",
      "Epoch 14/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8645 - accuracy: 0.7943 - val_loss: 0.8789 - val_accuracy: 0.7943 - loss: 0.8276 - accuracy - ETA: 3:24 - loss: 0.8252 - accuracy: 0.80 - ETA: 3:24 - loss: 0.8247 - accuracy: 0.80 - ETA: 3:24 - loss: 0.8241 - accuracy: 0.80 - ETA: 3:24 - loss: 0.8235 - accura - ETA: 3:23 - loss: 0.8267 - accuracy: 0.80 - ETA: 3:23 - los - - ETA - ETA: 1:17 - l - ETA: 1:06 - l - ETA: 1:03 - loss: 0.8395 - accura - ETA: 1:02 - loss: 0.8404 - accuracy: 0. - ETA: - ETA: 48s - loss: 0.8457 - accuracy - ETA: 47s - loss: 0.8445 - a - ETA: 44s - loss - ETA: 39s - los - ETA: 34s - loss: 0.8616 - accur - ETA: 32s - loss: 0.8670 - accuracy: 0 - ETA: 31s - loss: 0. - ET - ETA: 11s - loss: 0.8651 - accuracy:  - ETA: 10s - loss: 0.86\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8666 - accuracy: 0.7938 - val_loss: 0.8789 - val_accuracy: 0.7943: 6:07 - loss: - ETA: 5:24 - loss: 0 - ETA: 5:21 - loss: 0.797 - ETA: 5:19 - ETA: 3:55 - loss: 0.8534 - accuracy - ETA: 3:55 - loss: - ETA: 3: - ETA: 3:40 - loss: 0.8645 - ac - ETA: 3:22 - loss: 0 - ETA: 3:20 - loss: 0.863 - ETA: 3:18 - loss: 0.8675 - accuracy - ETA: 3:17 - ETA: 3:10 - - ETA: 3:07 - loss: 0.8876 - ac - ETA: 3:05 - l - ETA: 3:02 - loss: 0.8849 - accuracy: 0.78 - ETA: 3:02 - loss: 0.8862 - ac - ETA: 3:01 - loss: 0.8843 - accu - ETA: 3:00 - loss: 0.8827 - accuracy: 0. - ETA: 3:00 - loss: 0.8833  - ETA: 2:58 - loss: 0.8872 -  - ETA - ETA: 2:53 - loss: 0.8816 - accuracy - ETA: 2:52 - loss: 0.881 - ETA: 2:50 - loss: 0.8825 - accuracy - ETA: 2:49 - los - ETA: 2:47 - loss: 0.8852 - accuracy:  - E - ETA: 2:34 - loss: 0.8948 - accuracy:  - ETA: 2:33 - - ETA - ETA - ETA: 1:57 - loss: 0 - ETA: 1:55 - loss: 0 - ETA:  - ETA: 1:49 - loss: 0.8911 - accuracy: 0. - ETA: 1:49 - loss: 0.8 - ETA: 1:47 - loss: 0.8855 - accuracy:  - ETA: 1:46 - loss: 0.8843  - ETA: 1: - ETA: 1:41 - loss: 0.8923 -  - E - ETA: 1:35 - - ETA: 1:24 - loss: 0.8927 - accuracy: 0. - ETA: 1:24 - ETA:  - ETA: 1:00 - loss: 0.8797 - a - ETA: 57s - loss: 0.8796 - accuracy: 0.78 - ETA: 57s - loss: 0.8811 - accuracy: 0. - ETA: 56s - loss: 0 - ETA: 43s - loss - ETA: 38 - ETA: 32s - loss: 0.8847 -  - ET - ETA\n",
      "Epoch 16/30\n",
      "2149/2149 [==============================] - ETA: 0s - loss: 0.8666 - accuracy: 0.7938 - ETA: 23s - loss: 0.8776 - accuracy - ETA: 22s - loss: 0.8775 - - ETA: 19s - loss: 0.8743 - accuracy: 0.7 - ETA: 18s - loss - ETA: 13s - loss: 0.8747 - acc - ETA: 1 - ETA: 7s - loss: 0.8674 - accuracy - ETA - ETA: 2s - loss: - ETA: 0s - loss: 0.8665 - accuracy: \n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8666 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943\n",
      "Epoch 17/30\n",
      "2149/2149 [==============================] - 425s 198ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943s - lo - ETA: 27s - l - ETA: 22s - lo - ETA: 17s - - ETA: 2s - loss:\n",
      "Epoch 18/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8643 - accuracy: 0.7943 - val_loss: 0.8788 - val_accuracy: 0.7943 0.8430 - accuracy: 0. - ETA: 5:27 - loss: 0.8 - ETA: 5:25 - l - ETA: 5:18 - loss: 0.8587 -  - ETA: 5:17 - loss: 0.8531 - accu - ETA: 5:16 - - ETA:  - ETA: 5: - ETA: 4:19 - loss: 0.8710  - ETA: 4:17 - loss: 0.8779 - accuracy: 0.78 - ETA: 4:17 - loss: 0.8770 - accu - ETA: 4:03 - loss: 0.8 - ETA: 4:01 - loss: 0.8723 -  - ETA: 4:00 - loss: 0.8662 - accuracy: 0.79 - ETA: 3: - ETA: 3:52 - loss: 0.8583  - ETA: 3:50 - loss: 0.8541 - accura - ETA: 3:49 - loss: 0.8531 - ac - ETA: 3:43 - loss: 0.8580 - accuracy: 0.79 - ETA: 3:43 - loss: 0 - ETA: 3:41 - - ETA: 3:34 - loss: 0.8985 - accuracy:  - ETA: 3:33 - loss: 0.8965 - accu - ETA: 3:32 - loss: 0.8980 - accuracy:  - ETA: 3:32 - loss: 0.8984 - ac - ETA:  - ETA: 3: - ETA: 2:58 - loss: 0.8 - ETA: 2:56 - loss: 0.896 - ETA: 2:54 - - ETA: 2:51 - - ETA: 2:31 - loss: 0.8 - ETA: 2:29 - loss: 0.8834  - - E - ETA: 2:11 - loss: 0.8898 - accuracy: 0.78 - ETA: 2:10 - loss: 0.889 - ETA: 2:09 - loss: 0.8 - ETA: 2:07 - loss: 0.8873 - ac - ETA: 2:05 - l - ETA: 1:58 - loss: 0.8807 - accu - ETA: 1:57 - loss: 0.8860 - ac - ETA: 1:47 - loss: 0 - ETA: 1: - ETA: 1:42 - loss: 0.8863 - accu - ETA: 1:41 - - ETA: 1:25 - loss: 0.876 - ETA: 1:23 - loss: 0.8725 - accuracy:  - ETA: 1:22 - loss: 0.8713 - ac - ETA: 1:21 - loss: 0 - ETA: 1:19 - loss: 0 - ETA: 1:17 - los - ETA: 1:14 - loss: 0.8746 - accuracy:  - ETA: 1:13 - loss: 0.874 - ET - ETA: 59s - loss: 0.8 - ETA: 55s - loss: - ETA: 50s - loss: 0.8684 - accuracy:  - ETA: 49s - loss:  - ET - ETA: 37s \n",
      "Epoch 19/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943.7672 - accura - ETA: 5:46 - loss: 0.7877 - accuracy: 0.83 - ETA - ETA: 5:38 - loss: 0.8119 - ac - ETA: 5:37 - l - ETA: 5:26 - loss: 0.8697 - ac - ETA: 5:24 - loss: 0.8748  - ETA: 5:23 - loss: 0.8808 - accu - ETA: 5:22 - loss: 0.8863 -  - ETA: 5:20 - loss: 0.8 - ETA: 5:18 - - E - ETA: 5:11 - loss: 0.8598 - accuracy - ETA:  - ETA: 5:07 - loss: 0.8676 -  - ETA: 5:06 - loss: 0.8647 - accuracy:  - ETA: 5:05 - loss: 0 - ETA: 5:03 - loss: 0 - ETA: 5:01 - loss: 0.8570 - accuracy: 0. - ETA: 5:00 - loss: 0.8545 - accuracy: 0.80 - ETA: 5:00 - ETA:  - ETA: 4:53 - loss: 0.853 - ETA: 4:51 - loss: 0.8688 - accura - ETA: 4: - ETA: 4:47 - los - ETA: 4:45 - loss: 0.8629 - accuracy: 0.80 - ETA: 4: - ETA: 4:41 - - ETA: 4:38 - loss: 0.8634 - accuracy:  - ETA: 4:38 - loss: 0.8674 - accuracy: 0. - ETA: 4:37 - loss: 0 - ETA: 4:18 - loss: 0.873 - ETA: 4:16 - loss: 0.870 - ETA: 4: - ETA: 3:41 - loss: 0.8625 - accu - ETA: 3:40 - loss: 0.8616 - accuracy - ETA: 3:39 - loss: 0.8 - ETA: 3:37 - - ETA: 3:34 - loss: 0.8667 - accu - ETA: 3:33 - loss: 0.8 - E - ETA: 3:27 - loss: 0.8769 - accuracy: 0.79 - ETA: 3:27 - loss: 0.8782 - accuracy: 0.79 - ETA: 3:26 - - ETA: 3:23 - loss: 0.8732 - accuracy:  - ETA: 3:23 - loss: 0.871 - ETA: 3:08 - loss: 0.8732 - accuracy:  - ETA: 3:08 - loss: 0.8770 - ac - ETA: 3:06 - loss: 0.875 - ETA: 2:56 - l - ETA: 2:53 - loss: 0 - ETA - ETA: 2:43 - ETA - - ETA: 1:49 - loss: 0.8526 - accuracy: 0. - ETA: 1:40 - loss: 0.8444 - accu - ETA: 1:39 - loss: 0.8421 -  - ETA: 1:38 - loss: 0.8469  - ETA: 1:36 - - ETA: 1:33 - - ETA: 1:09 - loss: 0.8580 - accuracy: 0.79 - ETA: 1:09 - loss: 0.8577  - ETA: - ETA: 59s - lo - ETA: 53s - loss - ETA: 48s - loss: 0.85 - ETA: 44s - los - ETA: 39s - loss: 0.86 - ETA: 35s - loss: 0. - ETA: - ETA: 24s - loss: 0.8583 - accu - ETA: 22s -  - ETA: 16s - loss: 0.8689 - accuracy: 0.7 - ETA: 15s - loss: 0.8694 - ac - ETA: 13s - loss: 0.8689 - accuracy: 0.7 - ETA: 12 - ETA: 3s - l - ETA: 1s - loss: 0.8661 - ac\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943 - ETA: 5:37 - - ETA:  - ETA: 5:30 - loss: 0.9684 - accuracy - ETA: 5:30 - - ETA: 4:40 - loss: 0.9169 -  - E - ETA: 4:22 - loss: 0.9376 -  - ETA: 4:20 - loss: - ETA: 4:18 - loss: 0.9467 -  - ETA: 4:16 - loss: 0.9549 - accuracy: 0.77 - ETA: 4:12 - loss: 0.9 - ETA: 4:10 - loss: 0.9558 - accuracy: 0. - ETA: 4:09 - loss: - ETA: 4:07 - ETA: 4:04 - loss: 0.9586 - accuracy:  - ETA: 4:03 - loss: 0.9558 -  - ETA: 3:40 - loss: 0.9263 - accuracy - ETA: 3:40 - loss: 0.9 - ETA: 3:38 - loss: 0.9234 - accuracy:  - ETA: 3:37 - loss: 0.9212 - accuracy - - ETA: 3:24 - loss: 0.908 - ETA: 3:22 - loss: 0.907 - ETA: 3:11 - loss: 0.9019 - accuracy - ETA: 3:11 - loss: 0.8995 - accuracy: 0. - ETA: 3:10 - loss: 0.898 - ETA: 3:08 - - ETA: 2:48 - loss: 0.8816 - accuracy: 0. - E - ETA: 2:44 - loss: 0.8869 - accuracy: 0.78 - ETA: 2:44 - loss: 0.8880  - ETA: 2:34 - loss: 0.9011 - accuracy - ETA: 2:33 - l - ETA: 2:30 - loss: 0.8963 -  - ETA: 2: - ETA: 2:25 - loss: 0.8925 - accuracy - ETA: 2:24 - loss: 0.8906 - accuracy: 0.78 - ETA: 2:24 - l - ETA: 2:22 - loss: 0.886 - ETA: 2:20 - loss: - ETA: 2:00 - loss: 0.8 - ETA: 1:58 - los - ETA: 1: - ETA: 1:31 - loss: 0.8737 - accura - ETA: 1:30 - loss: 0 - ETA: 1:28 - loss: 0.8721 - accuracy: 0.79 - ETA: 1:27 - loss: 0.8 - ETA: 1:25 - loss: 0.8750 - ac - ETA: 1: - ETA: 1:21 - loss: 0.8791 - accuracy - ETA: 1:20 - loss: 0.8787 - accu - ETA: 1:19 - loss: 0.8777 - accuracy - ETA: 1:18 - loss: 0.8762  - ETA: 1:16 - loss: 0.8742 - accuracy: 0.79 - ETA: 1:16 - loss: 0.8738 - ac - ETA - ETA: 1:11 - loss: 0.8 - ETA: 1:09 - loss: 0.8719 - accuracy: 0.79 - ETA: 1:09 - loss: 0.8731 - accu - ETA: 1:04 - los - ETA: 1:01 -  - ETA: 57s - loss: 0.8844 - accuracy: 0 - ETA: 56s - loss: 0.8852 - accuracy: - ETA: 55s - loss: 0.8854 -  - ETA: 52s - loss: 0.8799 - accuracy:  - ETA: 51s - - ETA: 45s - loss: 0. - ETA: 40 - ETA: 34s - - ETA: 28s - loss: 0.86 - ETA: 24s - loss: 0.8653 - accuracy: 0.7 - ETA: 23s - loss: 0.8654 - accu - ETA: 21s - loss: 0.8662 - accuracy: 0 - ETA: 20s - loss: 0.8683 - - ETA: 17s - loss: 0.8734 - accuracy:  - ETA: 16s - loss: 0.8728  - ETA: 13s  - ETA: 8s - loss: 0.8693 - accuracy: 0. - ETA: 7s - loss: 0.8687 - ac - ETA: 6s - loss: 0.8691 - accura - ETA: 5s - loss: 0.8685 - accuracy - - ETA: 1s - loss: 0.8672 - ac\n",
      "Epoch 21/30\n",
      "2149/2149 [==============================] - ETA: 0s - loss: 0.8664 - accuracy: 0.7938   ETA: 5:31 - loss: - - ETA: 5:25 - loss: 0.7684 - accu - ETA: 5:24 - l - ETA: 5:21 - loss: 0.7625 - accuracy: 0.82 - ETA: 5:21 - loss: 0.7665 - accuracy: 0. - ETA: 5:20 - loss: 0.7652 - accu - ETA: 5:19 - loss: 0.7622 - accuracy: 0.81 - ETA: 5:19 - loss: 0.7609 - accuracy: 0. - ETA: 5:19 - loss: 0.7585 - accuracy - ETA: 5:18 - loss: 0.7618 -  - ETA: 5:16 - loss: 0.7522  - ETA: 5:15 - - ETA:  - ETA: 5:08 - loss: 0.7617 - ac - ETA: 5:07 - loss: 0.7589 -  - ETA: 5:06 - loss: 0.7731 - accu - ETA: 5:04 - loss: 0.7666 - accura - ETA: 5:04 - los - ETA: 5:01 - loss: 0.7721 - ac - ETA: 5:00 - loss: 0.7 - ETA: 4:45 - loss: 0.7979 - ac - ETA: 4:44 - loss: 0.7982 - accuracy: 0. - ETA:  - ETA: 4:35 - l - ETA: 4:33 - loss: 0.7862  - - ETA: 4: - ETA: 4:24 - l - ETA: 4:12 - - ETA: 4:09 - loss: 0.8174 - accuracy: 0. - ETA - E - ETA: 3:44 - loss: 0.8223 - accura - ETA: 2:56 - ETA: 2:53 - loss: 0.8809 - accuracy: 0. - ETA:  - ETA: 56s - loss: 0.85 - ETA: 53s - loss: 0.8603 - accuracy: 0 - ETA: 52s - loss: 0.8 - ETA:  - ETA - ETA: 3 - ETA: 5s - loss: 0.867 - ETA: 4s - los - ETA: 1s - loss: 0.8657 - accuracy:  - ETA: 0s - loss: 0.8669 - accura\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943\n",
      "Epoch 22/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8663 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943s: 0.8316 - accu - ETA: 3:57 - loss: 0.8360 - accuracy:  - ETA: 3:56 - los - ETA - ETA: 3:50 - loss: 0.8328 -  - ETA: 3:48 - l - ETA:  - ETA: 3:42 - loss: 0.8 - - ETA:  - ETA: 1:20 - loss: 0.8575 - accuracy: 0.79 - ETA: 1:20 - E - ETA: 1:08 - loss: 0.8724 - accu - ETA:  - ETA: 1:04 - - ETA - ET - ETA: 31s -  - ETA: 25s - loss: 0.8757 - accurac - ETA: 23s - loss: 0.8738 - accuracy: 0.79 - ETA: 23s - loss: 0.8732 - accu - ETA: 21s - loss: 0.8718 - accurac - ETA: - ETA: 12s - loss: 0.8635 - accuracy: 0 - ETA: 11s - lo\n",
      "Epoch 23/30\n",
      "2149/2149 [==============================] - 426s 198ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943 - ETA:  - ETA: 2:24 - - ETA: 2:21 - loss: 0.8566 - accuracy:  - ETA: 2:20 - loss: 0.858 - ETA: 2:14 - loss: 0.8558 - accuracy:  - ETA: 2:13 - loss: 0.8574 - accuracy: 0.79 - ETA: 2:13 - loss: 0.8 - ETA: 2:11 - loss: 0.8 - ETA: 2:09 - ETA: 2:06 - loss: 0.8594 - accu - ETA: 2:05 - loss: 0.8614 -  - - ETA: 1:51 - loss: 0.866 - ETA: 1:49 - loss: 0.8633 - accuracy - ETA: 1:48 - loss: 0 - ETA: 1:20 - loss: 0.8647  - ETA: 1:14 - loss: 0.8639 - accuracy - ETA:  - ETA: 1:06 - loss: 0.8646  - ETA: 1:04 - loss: 0.864 - ETA: 1:02 - - ETA: 59s - loss: 0.8654 -  - ETA: 40s - ETA: 17s - loss:  - ETA: 12s - loss: 0.8623 - accur - ETA - ETA: 6s - loss: 0.8 - ETA: 0s - loss: 0.8660 - accuracy: \n",
      "Epoch 24/30\n",
      "2149/2149 [==============================] - 427s 198ms/step - loss: 0.8654 - accuracy: 0.7943 - val_loss: 0.8788 - val_accuracy: 0.794304 - loss: 0.9466  - ETA: 6:02 - l - ETA: 6:00 - loss: 0.9564 - accuracy: 0.77 - ETA: 5:59 - loss: 0.9734 -  - ETA: 5:54 - loss: 0.9 - ETA: 5:52 - loss: 0.946 - ETA: 5:46 - los - ETA: 4:31 - los - - ETA: 4:20 - loss: 0.8002 - accuracy: 0. - ETA: 4:20 - loss: 0 - ETA: 4:09 - loss: 0.8148  - ETA - ETA: 3:55 - loss: 0.8210 - accuracy:  - ETA: 3:55 - loss: 0 - ETA: 3:52 - loss: 0.8314  - ETA: 3:51 - loss: 0.8320 -  - ETA - ETA: 2:59 - loss: 0.862 - ETA: 2:57 - loss: 0.8 - ETA: 2:55 - loss: - ETA: 1:18 - loss: 0.8354  - ETA: 1: - ETA: 1:13 - loss: 0.8435 - ac - ETA: 1:12 - loss: 0.8453 - accuracy - ETA: 1:11 - loss: 0.8440 - accuracy: 0. - - ETA: 1:07 - loss: 0.8463 - accuracy - ETA: 1:06 - loss: 0.844 - ETA: 1:04 - - ETA: 1:01 - loss: 0.8505 - accuracy:  - ETA: 1:01 - loss: 0.8495 - accuracy: 0.79 - ETA: 1:00 - loss: 0.8491 - accura - ETA: 1:00 - loss: 0.8475 - accu - ETA: 57s - lo - ETA: 52s - loss: 0.8542 - accuracy: 0.797 - ETA: 52s - l - ETA: 46s - ETA: 32s - loss: 0.8647 - E - ETA: 12s\n",
      "Epoch 25/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8663 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943  - ETA: 12s - loss: 0.8744 - accuracy:  - ETA: 11s - l\n",
      "Epoch 26/30\n",
      "2149/2149 [==============================] - ETA: 0s - loss: 0.8664 - accuracy: 0.7938   ETA: - ETA: 54s - loss: 0.8462 - accuracy - ETA: 52s - loss: 0.8459 - accuracy - ETA: 51s - loss: 0.8461 -  - ETA: 39s - loss: 0.8367 - accuracy: - ETA: 38s - loss: 0.8363 - ETA: 26s - loss: 0.8394 - ac - ETA: 24s - loss: 0.8409 - - ETA: 20s - loss: 0.8481 - accuracy: 0.79 - ETA: 20s - loss: 0.8492 - accuracy: 0.797 - ETA: 2 - ETA: 13s - loss: 0.8591 - accuracy: - ETA: 12s - \n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "2149/2149 [==============================] - 427s 198ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943\n",
      "Epoch 27/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943s - loss: 0.8713 - accuracy: - ETA: 45s - loss: 0.8704  - ETA: 42s - loss: 0.8669 - - ETA: 39s - loss: 0.8688 - accuracy: 0.7 - ETA: 38s - loss: 0.8678 - - ETA: 1s - loss: 0.8\n",
      "Epoch 28/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8645 - accuracy: 0.7943 - val_loss: 0.8788 - val_accuracy: 0.7943 loss: 0.833 - ETA: 2:23 - los - ETA: 2: - ETA - ETA: 1:14 - - ETA: - ETA: 25s - loss: 0.8663 - ETA\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943 18s - loss: 0.8626 - accuracy: 0 - ETA: 1 - ETA: 10s - loss: 0.8704  - ETA: 8s - loss: 0.8695 - accura - E\n",
      "Epoch 30/30\n",
      "2149/2149 [==============================] - 427s 199ms/step - loss: 0.8664 - accuracy: 0.7938 - val_loss: 0.8788 - val_accuracy: 0.7943\n"
     ]
    }
   ],
   "source": [
    "history  = model.fit(train_batches, \n",
    "         steps_per_epoch=train_batches.n//train_batches.batch_size,\n",
    "         validation_data=val_batches, \n",
    "         validation_steps=val_batches.n//val_batches.batch_size, \n",
    "         epochs=30, \n",
    "         #class_weight = {0:1.0893296433,1:1.00753697383,2:2.178659287,3:2.219611529,4:0.2173846343,5:2.63578869,6:4.15786385,7:1.549650044,8:1.880307856,9:0.4193300189,10:2.512411348},\n",
    "         verbose=1,\n",
    "         callbacks = callbacks)\n",
    "\n",
    "# 8:0.10495873,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd7b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29fb6220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8597 images belonging to 12 classes.\n",
      "WARNING:tensorflow:From <ipython-input-29-ce2809eedb6c>:9: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_data_generator = test_generator.flow_from_directory(\n",
    "    'D:/dataset/Test', # Put your path here\n",
    "     target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    shuffle=False)\n",
    "test_steps_per_epoch = np.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
    "\n",
    "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cad5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data_generator.classes\n",
    "class_labels = list(test_data_generator.class_indices.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96f26e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06c3180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "              Air_trapping       0.00      0.00      0.00       136\n",
      "         Aortic_elongation       0.00      0.00      0.00       147\n",
      "                COPD_Signs       0.00      0.00      0.00       679\n",
      "       Calcified_granuloma       0.00      0.00      0.00        68\n",
      "       Callus_rib_fracture       0.00      0.00      0.00        66\n",
      "             Hiatal_hernia       0.00      0.00      0.00        56\n",
      "                  Kyphosis       0.00      0.00      0.00        35\n",
      "       Laminar_atelectasis       0.00      0.00      0.00        95\n",
      "                    Normal       0.79      1.00      0.89      6825\n",
      "          Pleural_effusion       0.00      0.00      0.00        79\n",
      "                 Scoliosis       0.00      0.00      0.00       352\n",
      "Vascular_hilar_enlargement       0.00      0.00      0.00        59\n",
      "\n",
      "                  accuracy                           0.79      8597\n",
      "                 macro avg       0.07      0.08      0.07      8597\n",
      "              weighted avg       0.63      0.79      0.70      8597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Havoc\\anaconda3\\envs\\padchest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Havoc\\anaconda3\\envs\\padchest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Havoc\\anaconda3\\envs\\padchest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e13b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padchest",
   "language": "python",
   "name": "padchest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
