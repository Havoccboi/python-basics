{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b99ab988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "import numpy as np\n",
    "#from imgaug import augmenters as iaa\n",
    "#import cv2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#import seaborn as sns\n",
    "import pandas as pd \n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae836231",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = r'D:/dataset/Train'\n",
    "VAL_PATH = r'D:/dataset/Test'\n",
    "BATCH_SIZE=16\n",
    "r=4\n",
    "c=4\n",
    "#CATEGORIES = ['Air_trapping', 'Aortic_elongation','COPD_Signs','Calcified_granuloma','Callus_rib_fracture','Hiatal_hernia','Kyphosis','Laminar_atelectasis','Normal','Pleural_effusion','Scoliosis','Vascular_hilar_enlargement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c644fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34387 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_batches = train_datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                                  class_mode='categorical', \n",
    "                                                  batch_size=BATCH_SIZE, \n",
    "                                                  target_size=(256, 256),\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=42\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d74671cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8597 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_batches = val_datagen.flow_from_directory(VAL_PATH,\n",
    "                                                class_mode='categorical', \n",
    "                                          \n",
    "                                                batch_size=BATCH_SIZE, \n",
    "                                                target_size=(256, 256),\n",
    "                                                shuffle=True,\n",
    "                                                seed=42\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dfaff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87192750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5420a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                6156      \n",
      "=================================================================\n",
      "Total params: 14,720,844\n",
      "Trainable params: 14,720,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def vgg():\n",
    "    base_model = VGG16(weights='imagenet',include_top=False,pooling='avg',input_shape=(256,256,3))\n",
    "    predictions=Dense(12,activation='softmax',trainable=True)(base_model.output)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=True\n",
    "    model=Model(inputs=[base_model.input], outputs=[predictions])\n",
    "    \n",
    "    optim = tf.keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-4)\n",
    "    loss_func = 'mae'\n",
    "    \n",
    "    model.compile(optimizer=optim,loss=loss_func,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=None\n",
    "model = vgg()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f70d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('adam_baseline_vgg.h5', monitor='val_accuracy', save_best_only=True, mode='max'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, verbose=1, patience=5, mode='max')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ba6d39c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2149/2149 [==============================] - 1333s 620ms/step - loss: 0.0351 - accuracy: 0.7907 - val_loss: 0.0344 - val_accuracy: 0.7939\n",
      "Epoch 2/20\n",
      "2149/2149 [==============================] - 501s 233ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7939\n",
      "Epoch 3/20\n",
      "2149/2149 [==============================] - 513s 239ms/step - loss: 0.0343 - accuracy: 0.7941 - val_loss: 0.0343 - val_accuracy: 0.7940\n",
      "Epoch 4/20\n",
      "2149/2149 [==============================] - 515s 239ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7939\n",
      "Epoch 5/20\n",
      "2149/2149 [==============================] - 513s 239ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7939\n",
      "Epoch 6/20\n",
      "2149/2149 [==============================] - 509s 237ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7938\n",
      "Epoch 7/20\n",
      "2149/2149 [==============================] - 512s 238ms/step - loss: 0.0343 - accuracy: 0.7939 - val_loss: 0.0343 - val_accuracy: 0.7940\n",
      "Epoch 8/20\n",
      "2149/2149 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.7940\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "2149/2149 [==============================] - 518s 241ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7938\n",
      "Epoch 9/20\n",
      "2149/2149 [==============================] - 513s 238ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7938\n",
      "Epoch 10/20\n",
      "2149/2149 [==============================] - 508s 237ms/step - loss: 0.0344 - accuracy: 0.7939 - val_loss: 0.0344 - val_accuracy: 0.7938\n",
      "Epoch 11/20\n",
      "2149/2149 [==============================] - 504s 235ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0343 - val_accuracy: 0.7941\n",
      "Epoch 12/20\n",
      "2149/2149 [==============================] - 504s 234ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7939\n",
      "Epoch 13/20\n",
      "2149/2149 [==============================] - 504s 234ms/step - loss: 0.0343 - accuracy: 0.7939 - val_loss: 0.0343 - val_accuracy: 0.7940\n",
      "Epoch 14/20\n",
      "2149/2149 [==============================] - 504s 235ms/step - loss: 0.0343 - accuracy: 0.7939 - val_loss: 0.0344 - val_accuracy: 0.7939\n",
      "Epoch 15/20\n",
      "2149/2149 [==============================] - 508s 236ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7939\n",
      "Epoch 16/20\n",
      "2149/2149 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.7940\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "2149/2149 [==============================] - 515s 239ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0343 - val_accuracy: 0.7940\n",
      "Epoch 17/20\n",
      "2149/2149 [==============================] - 532s 247ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0343 - val_accuracy: 0.7940\n",
      "Epoch 18/20\n",
      "2149/2149 [==============================] - 554s 258ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7938\n",
      "Epoch 19/20\n",
      "2149/2149 [==============================] - 550s 256ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0343 - val_accuracy: 0.7940\n",
      "Epoch 20/20\n",
      "2149/2149 [==============================] - 522s 243ms/step - loss: 0.0343 - accuracy: 0.7940 - val_loss: 0.0344 - val_accuracy: 0.7939\n"
     ]
    }
   ],
   "source": [
    "history  = model.fit(train_batches, \n",
    "         steps_per_epoch=train_batches.n//train_batches.batch_size,\n",
    "         validation_data=val_batches, \n",
    "         validation_steps=val_batches.n//val_batches.batch_size, \n",
    "         epochs=20, \n",
    "         verbose=1,\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd7b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29fb6220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8597 images belonging to 12 classes.\n",
      "WARNING:tensorflow:From <ipython-input-21-62a6ce625380>:9: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator()\n",
    "test_data_generator = test_generator.flow_from_directory(\n",
    "    'D:/dataset/Test', # Put your path here\n",
    "     target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    shuffle=False)\n",
    "test_steps_per_epoch = np.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
    "\n",
    "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cad5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data_generator.classes\n",
    "class_labels = list(test_data_generator.class_indices.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96f26e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06c3180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "              Air_trapping       0.00      0.00      0.00       136\n",
      "         Aortic_elongation       0.00      0.00      0.00       147\n",
      "                COPD_Signs       0.00      0.00      0.00       679\n",
      "       Calcified_granuloma       0.00      0.00      0.00        68\n",
      "       Callus_rib_fracture       0.00      0.00      0.00        66\n",
      "             Hiatal_hernia       0.00      0.00      0.00        56\n",
      "                  Kyphosis       0.00      0.00      0.00        35\n",
      "       Laminar_atelectasis       0.00      0.00      0.00        95\n",
      "                    Normal       0.79      1.00      0.89      6825\n",
      "          Pleural_effusion       0.00      0.00      0.00        79\n",
      "                 Scoliosis       0.00      0.00      0.00       352\n",
      "Vascular_hilar_enlargement       0.00      0.00      0.00        59\n",
      "\n",
      "                  accuracy                           0.79      8597\n",
      "                 macro avg       0.07      0.08      0.07      8597\n",
      "              weighted avg       0.63      0.79      0.70      8597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Havoc\\anaconda3\\envs\\padchest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Havoc\\anaconda3\\envs\\padchest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Havoc\\anaconda3\\envs\\padchest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e13b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padchest",
   "language": "python",
   "name": "padchest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
